---
tags:
  - weekly
  - logs
aim: Ragas
advice: 
aliases:
  - weekly plan
---

### Focus 

- [ ] [[Codecrafters Kafka]]
- [ ] [[Rust Ardan Labs]]
- [ ] [[Ragas in Elixir]]
	- [ ] [[ML readings]]


Write an accomplishment BIO for yourself. 
- [ ] like this https://zed.dev/team

### Blogs read this week 

<h6 class="h6">  Database - NEON </h6> 

- [ ] https://neon.tech/blog/architecture-decisions-in-neon

<h6 class="h6">  Rust Async Runtimes  </h6> 

* When to use traits in Rust ?
1. These types are technical details the programmers understand, but does not affect how the business logic works at all. So we have them behind traits.

* Radix Humanyun 
Task, Spawner, Exectuor, Waker 

* Monoio (io-uring based rust executor)

<h6 class="h6">  Deterministic Simulation Testing of LibSQL</h6> 
- https://github.com/penberg/hiisi

https://turso.tech/blog/a-deep-look-into-our-new-massive-multitenant-architecture

> But for our DST-based server, we decided to just use a manually crafted event loop with a callback system, and stick to sync Rust.


<h6 class="h6"> Composable data stack at FB </h6> 

- https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/
- https://engineering.fb.com/2023/03/09/open-source/velox-open-source-execution-engine/
 
Pavex : 
https://www.youtube.com/watch?v=cMea6IMRk2s

- https://materializedview.io/p/fizzbee-tla-and-formal-software-verification
- https://www.rilldata.com/blog/the-rise-of-the-declarative-data-stack
- https://materializedview.io/p/small-batch-artisanal-etl-is-back
- https://benpfaff.org/papers/index.html -- guy behind feldera

### Blogs Writing this week 

- [ ] Rust exectuor 
- [ ] Composite Indexes in SQL - explained with Example


#### todo

- [x] setup tmux system for personal work 
	- [ ] ragas
	- [ ] kafka codecrafters
	- [ ] blogging - tasting_curries
- [x] setup tmux for professional work 
	- [ ] ardan labs course rust 
	- [ ] jonhoo videos rust 
	- [x] CREATE VIEWS in obsidian for 
		- [x] files edited today
		- [x] files edited this week
- [ ] [[Event Sourcing]] and Commanded books
- [ ] Setup Blog - Astro + Obsidian setup. The best! 
	- [x] git repo setup 
	- [x] build astro locally? 
		- [ ] cleanup and migrate blog posts
			- [x] draft all shriram's posts
			- [ ] publish first post
		- [ ] cleanup shriram's references
			- [x] image
			- [x] socials
			- [ ] blog live link
			- [ ] company name etc 
			- [x] Name from author etc 
	- [ ] BlogPost: Evals and setting it up in elixir
	- [ ] obsidian local setup
	- [ ] mobile setup obsidian
- [ ] Shivani - Ash Framework - ash_table for quickly updating the views.
	- [x] setup ash with postgres etc. 
	- [ ] domain modelling
	- [ ] migrations
	- [ ] seed data
	- [ ] ash_table
- [ ] Balu skype 
- [ ] Database series 
	- [ ] from todo microsoft
- [ ] OS Series
- [ ] 

Daily Checklist 
- [ ] stord 
	- [ ] checked pr comments
- [ ] shivani 
	- [ ] prepared topic for practice?
	- [ ] 




Casey Muratory with prime - Arm64 
- IPC - instruction per cycle of cpu 
- decode (parsing ) - the instructions given to the CPU 
- ARM doesn't need to guess / parse / decode where the instructions end. Unlike Intel (x86) 
- Intel produced binary sizes -- lower than arm
 - also, speed is faster ? 
- having giant binaries -> 
 - instruction cache (32k) - in cpu - gets invalidated so quickly 
 - cpu waits for your code to come into instruction cache. 
- Huffman trees - I bit to encode ?



- [ ] PR merged 4209?
- [ ] PR wms-ui 
- [ ] arpit tracks + dragdrop 
- [ ] Blogs
	- [ ] ractor rust presentation
	- [ ] Handling Overload blog
	- [ ] PAPERS 
		- [ ] Z-sets and handling incremental updates - slateDB discord?
		- [ ] Distributed Transactions [Epoxy](https://petereliaskraft.net/blog/epoxy)
		- [ ] [Data Parallel ACtors ](https://github.com/stanford-futuredata/Uniserve)
		- [ ] [POP - Solving Large-Scale Granular Resource Allocation Problems](https://github.com/stanford-futuredata/POP)
		- [ ] [Accelerating Aggregates queries with expensive predicates](https://github.com/stanford-futuredata/abae)
	- [ ] RAG
		- [ ] [Auto eval RAG](https://github.com/stanford-futuredata/ARES)
	- [ ] OS Series
		- [ ] Thread per core model - datadog blog 
		- [ ] [Arachne](https://github.com/PlatformLab/Arachne) - core aware thread management
	- [ ] Uber's data blogs?  
		- [ ] https://www.uber.com/en-IN/blog/making-ubers-experiment-evaluation-engine-100x-faster/?uclick_id=3e065ccb-9c82-4f4d-92d2-7fff8b43499c
		- [ ] https://www.uber.com/en-IN/blog/pinot-for-low-latency/?uclick_id=3e065ccb-9c82-4f4d-92d2-7fff8b43499c
	- [ ] Pinot - Joins at scale! 
		- [ ] 
	- [ ] [ETL at Uber](https://www.uber.com/en-IN/blog/sparkle-modular-etl/?uclick_id=3e065ccb-9c82-4f4d-92d2-7fff8b43499c)
- [ ] Shivani - Ash Framework setup
- [ ] Machine Learning
	- [ ] [Serving Models Via ONNX Runtime in browser?](https://huggingface.co/briaai/RMBG-1.4/tree/main/onnx) and transformers.js 
	- [ ] 



##### Zed Podcast
Editing the file.
- Rope data structure and CRDT = editing huge files in Zed
- linebreaks - index that instead of finding the linebreak in the string  (vec\[u8\]) in rust - Navigating the file.

> invite people to block time in your calendar -- and then hack together on github issues - zed.

##### Matic Robots - Rust 

- FFI Rust on vendor C lib . rewrite the product stack 
	- if quality is important, rust is important
- Good hardware -> integrate via FFI Rust
	- Raw images from camera => consume directly (on device)
	- Small microcontroller for the motors 
	- Local wifi to talk to phone?
- Basically this is computer + camera + IR 
- innovation tokens  - boring tech 
- Memory safety?
- VSLAM Algo
- Real Time -- what is hard?
	- cost vs CPUs optimise
- Preventing regressions is the hardest tech. 
	- in custom piece of hardware => put hardware in the test loop to know if the regression has happened. (easy for chips, moving hardware is harder to test :p )
- Error handling on Device
	- retry after sometime -- access logs 
- cargo deny --
	- uses unsfae code? actively maintained? ... so on??? 
	- 
- 



What is RISC-v?
- ESP32 boards intro 
- esp-idf + Rust 
- bare metal








### Eclipse Zenoh 
- 


















##### Things to believe in 
- https://nat.org/

##### AI on any Infra
- https://x.com/skypilot_org
- 


### Ash Prompts


```
defmodule AshHq.Blog.Post do
  @moduledoc "A blog post. Uses the AshBlog data layer and therefore is static"
  use Ash.Resource,
    domain: AshHq.Blog,
    otp_app: :ash_hq,
    data_layer: AshBlog.DataLayer,
    extensions: [AshHq.Docs.Extensions.RenderMarkdown, AshAdmin.Resource]

  require Ash.Query

  render_markdown do
    render_attributes body: :body_html
  end

  admin do
    table_columns [:slug, :title, :state, :created_at, :id]

    form do
      field :body do
        type :markdown
      end
    end
  end

  actions do
    default_accept :*
    defaults [:create, :read, :update]

    read :published do
      argument :tag, :ci_string

      prepare build(sort: [created_at: :desc])

      filter expr(
               state == :published and
                 if is_nil(^arg(:tag)) do
                   true
                 else
                   ^arg(:tag) in type(tag_names, ^{:array, :ci_string})
                 end
             )
    end

    read :by_slug do
      argument :slug, :string do
        allow_nil? false
      end

      get? true

      filter expr(slug == ^arg(:slug) or ^arg(:slug) in past_slugs)
    end
  end

  attributes do
    uuid_primary_key :id

    attribute :tag_line, :string do
      public? true
      allow_nil? false
      constraints max_length: 250
    end

    attribute :tag_names, {:array, :ci_string} do
      public? true

      constraints items: [
                    match: ~r/^[a-zA-Z]*$/,
                    casing: :lower
                  ]
    end

    attribute :author, :string do
      public? true
      allow_nil? false
    end

    attribute :body_html, :string do
      public? true
      writable? false
    end

    timestamps()
  end

  relationships do
    has_many :tags, AshHq.Blog.Tag do
      public? true

      manual fn posts, %{query: query} ->
        all_tags = Enum.flat_map(posts, &(&1.tag_names || []))

        tags =
          query
          |> Ash.Query.unset([:limit, :offset])
          |> Ash.Query.filter(name in ^all_tags)
          |> Ash.read!()

        {:ok,
         Map.new(posts, fn post ->
           {post.id, Enum.filter(tags, &(&1.name in post.tag_names))}
         end)}
      end
    end
  end

  code_interface do
    define :published
    define :by_slug, args: [:slug]
  end

  changes do
    change fn changeset, _ ->
             Ash.Changeset.after_action(changeset, fn _, %{tag_names: tag_names} = record ->
               all_post_tags =
                 AshHq.Blog.Post.published!()
                 |> Enum.flat_map(&(&1.tag_names || []))

               notifications =
                 Enum.flat_map(
                   tag_names || [],
                   &elem(AshHq.Blog.Tag.upsert!(&1, return_notifications?: true), 1)
                 )

               destroy_notifications =
                 AshHq.Blog.Tag.read!()
                 |> Enum.flat_map(fn tag ->
                   if to_string(tag.name) in all_post_tags do
                     []
                   else
                     AshHq.Blog.Tag.destroy!(tag, return_notifications?: true)
                   end
                 end)

               {:ok, record, notifications ++ destroy_notifications}
             end)
           end,
           on: [:create, :update]
  end
end
```
this is a basic blog post with Ash. Post is called Resource.

this is custom dsl for defining Resources. Here is a brief description of it. 
1. `changes do .. end  ` - section represents the changesets and validations on the data
2. `code_interface` - defines public API exposed from the module
3. `relationships` are postgres relationships between this resource and other resources
4. `attributes` are the columns of the postgres table
5. `actions` are the CRUD related functions defined on the resource.

----- 

Use the above and write Ash Resources based on the following SQL queries. Ensure that you have `attributes` and `relationships` sections included.


```sql
CREATE TABLE topics (
2    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
3    name TEXT NOT NULL,
4    parent_id BIGINT REFERENCES topics(id) ON DELETE CASCADE
5);
6
7CREATE TABLE topic_progress (
8    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
9    topic_id BIGINT REFERENCES topics(id) ON DELETE CASCADE,
10    progress_percentage NUMERIC(5, 2) NOT NULL CHECK (progress_percentage >= 0 AND progress_percentage <= 100),
11    progress_date DATE NOT NULL
12);
13
14CREATE TABLE topic_revisions (
15    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
16    topic_id BIGINT REFERENCES topics(id) ON DELETE CASCADE,
17    revision_number INT NOT NULL,
18    revision_date DATE NOT NULL
19);
```

##### Not important Not Urgent

- 




























