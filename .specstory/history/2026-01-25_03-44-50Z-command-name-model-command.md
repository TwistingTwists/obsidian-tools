<!-- Generated by SpecStory, Markdown v2.1.0 -->

# 2026-01-25 03:48:35Z

<!-- Claude Code Session 49732e28-9fed-4322-b7bf-5bde1519352b (2026-01-25 03:48:35Z) -->

_**User (2026-01-25T03:48:35.114Z)**_

<command-name>/model</command-name>
            <command-message>model</command-message>
            <command-args></command-args>

_**User (2026-01-25T03:48:35.114Z)**_

<local-command-stdout>Set model to [1msonnet (claude-sonnet-4-5-20250929)[22m</local-command-stdout>

_**User (2026-01-25T03:48:35.121Z)**_

<local-command-caveat>Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.</local-command-caveat>

_**User (2026-01-25T03:53:23.481Z)**_

read the doris md file -> and tell me how do you plan to implement all of that ? 

we want to discuss that at a PRD level - so that you can quickly write out the phase wise features that will be implemented. we may want to implement that in elixir / rust (that decision comes later) 

first order of business is to get to a plan so that we can implement that in phased manner. 

----

voice AI is an important part of it. also, we may have a lot of different applications (based on my household) in future -> so keep in mind that we will want to keep the directory / folder / project structure so that we can have some core modules, that interact with other modules based on traits / interfaces / contracts -> so that all the good practices are enforced. 

----

this software will evolve a lot and fast. so we wnat to focus on flexibiltiy and good engineering practices in software architecture from day 1

---

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:37.334Z)**_

<think><details><summary>Thought Process</summary>
The user is asking me to:
1. Read a DORIS md file
2. Create a PRD-level implementation plan
3. Think about phased features
4. Consider Elixir/Rust (decision later)
5. Focus on voice AI as important
6. Plan for multiple household applications
7. Design with core modules + interfaces/traits/contracts
8. Prioritize flexibility and good software architecture from day 1

Let me first find and read the DORIS md file.

I should check if there's a skill that applies here. Let me think:
- "brainstorm" or "brainstorming" - this is about exploring requirements and design before implementation
- "write-plan" - creating detailed implementation plan
- "using-superpowers" - checking for skills

This feels like it could be a brainstorming task (exploring requirements, design) OR a write-plan task (creating implementation plan). Let me check the skill descriptions:

From the system reminder:
- superpowers:brainstorm: "You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores requirements and design before implementation."
- superpowers:write-plan: "Create detailed implementation plan with bite-sized tasks"
- superpowers:brainstorming: "You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores user intent, requirements and design before implementation."

This is definitely creative work - planning an entire system architecture and PRD. The user wants to "discuss at a PRD level" and "get to a plan". This sounds like brainstorming first (explore requirements, design) before writing a detailed plan.

According to the rules: "Process skills first (brainstorming, debugging) - these determine HOW to approach the task"

So I should use the brainstorming skill first. Let me invoke it.
</details></think>

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:38.124Z)**_

I'll help you create a PRD-level implementation plan for DORIS. Let me first read the markdown file and then use the brainstorming skill to explore the requirements and design approach.

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:38.535Z)**_

<tool-use data-tool-type="search" data-tool-name="Glob"><details>
<summary>Tool use: **Glob**</summary>
 pattern `**/*doris*.md`
```
/home/abhishek/Downloads/experiments/learnings/Home assistant - doris.md
```
</details></tool-use>

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:42.527Z)**_

<think><details><summary>Thought Process</summary>
Found the file. Now let me read it.
</details></think>

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:42.884Z)**_

<tool-use data-tool-type="read" data-tool-name="Read"><details>
<summary>Tool use: **Read**</summary>
 `./Home assistant - doris.md`
```
     1â†’
     2â†’avwgtiguy
     3â†’Doris: A Personal AI Assistant
     4â†’Built with Claude
     5â†’I've been working for the past 2 months on a personal AI assistant called Doris for my family. It started as a fun hobby project and has evolved into something my household actually uses daily. Figured I'd share what I've built in case anyone's interested or working on something similar.
     6â†’
     7â†’#What is it?
     8â†’Doris is a voice-first AI assistant that runs on a Mac Mini M4 Pro in my home. The main goal was to have something that:
     9â†’
    10â†’- Actually knows my family (names, preferences, schedules)
    11â†’- Remembers conversations across sessions
    12â†’- Integrates with the services we already use (Apple ecosystem, Home Assistant, Gmail)
    13â†’- Can be extended without rewriting everything
    14â†’
    15â†’#How it works
    16â†’The brain: Claude handles all the reasoning. I tried local models initially but found the quality gap too significant for family use. Claude Opus 4.5 for conversations, Haiku for background tasks to keep costs reasonable.
    17â†’
    18â†’#Voice pipeline
    19â†’- Wake word detection (tried Porcupine, then openwakeword, now using a custom approach based on Moonshine STT)
    20â†’- Groq Whisper for transcription (~200ms)
    21â†’- Azure TTS for speech output with expressive styles
    22â†’
    23â†’#Memory & Context Persistence
    24â†’This is the part I spent the most time on, and honestly the thing that makes the biggest difference in day-to-day use. The core problem: AI assistants have amnesia. Every conversation starts fresh which is useless for a family assistant that needs to know who we are.
    25â†’
    26â†’#How it works
    27â†’The memory system is a PostgreSQL database (Supabase) with pgvector for semantic search. Every memory gets embedded using Voyage AI's voyage-3 model. Currently sitting at 1,700+ memories.
    28â†’
    29â†’#Memory categories:
    30â†’- `identity` - Core facts: names, relationships, ages, birthdays
    31â†’- `family` - Context about family members, schools, activities
    32â†’- `preference` - How we like things done ("no cheerleading", "truth over comfort")
    33â†’- `project` - Things I'm working on (Doris itself is in here)
    34â†’- `decision` - Architectural choices, decisions made in past conversations
    35â†’- `context` - Recurring themes, background info
    36â†’- `health`, `financial` - Sensitive categories with appropriate handling
    37â†’
    38â†’#The bootstrap process
    39â†’Every conversation starts with a "bootstrap" call that loads ~700 tokens of core context. This happens before Doris even sees my message. The bootstrap includes:
    40â†’- Who I am and my family members
    41â†’- Communication preferences
    42â†’- Current date/time context
    43â†’- Active projects
    44â†’- Recent decisions (last few days)
    45â†’- Any relevant family notes
    46â†’
    47â†’So when I say "what's Levi doing this weekend", Doris already knows Levi is my youngest son before I finish the sentence.
    48â†’
    49â†’#Memory extraction
    50â†’After conversations, facts get extracted and stored. This happens a few ways:
    51â†’- **Explicit logging** - I can say "remember this" or "log this decision"
    52â†’- **Auto-extraction** - Haiku reviews conversations and pulls out facts worth remembering
    53â†’- **Session summaries** - Rich summaries of longer sessions with reasoning and open questions
    54â†’
    55â†’The extraction uses Claude Haiku to keep costs down. It categorizes, tags subjects, and assigns confidence scores.
    56â†’
    57â†’#Cross-client persistence
    58â†’This is where it got interesting and incredibly useful. The memory system is exposed via MCP, which means:
    59â†’- **Doris voice** on my Mac Mini
    60â†’- **Doris iOS app** on my phone
    61â†’- **Doris macOS app** on my laptop
    62â†’- **Claude Desktop** on any machine
    63â†’- **Claude Code** in my terminal
    64â†’
    65â†’...all share the same memory. I can have a conversation with Doris in the morning about a home project, then ask Claude Code about it that evening while working, and it knows the context. The memory is the unifying layer.
    66â†’
    67â†’#Technical details for the curious
    68â†’- **Database:** Supabase PostgreSQL + pgvector extension
    69â†’- **Embeddings:** Voyage AI voyage-3
    70â†’- **Search:** Hybrid - semantic similarity + keyword FTS, results merged
    71â†’- **MCP Server:** FastMCP on Railway, exposes 5 tools (bootstrap, query, log, facts, forget)
    72â†’- **Retrieval:** Bootstrap grabs core identity + recent context. Queries do semantic search with optional category filtering.
    73â†’
    74â†’The "forget" tool exists for corrections and privacy. It requires confirmation before actually deleting anything.
    75â†’
    76â†’#What makes it actually useful
    77â†’The key insight: memory isn't just used for storing facts, it's about having the right context at conversation start. A system that can answer "what did we talk about last week" is less useful than one that already knows the relevant parts of what we talked about last week before you ask anything.
    78â†’
    79â†’The bootstrap approach means Doris starts every conversation already oriented. She knows it's Friday, knows my kids' names and ages, knows I'm working on this project, knows I prefer direct communication. That baseline context changes how every response feels.
    80â†’
    81â†’#What it can actually do
    82â†’**Home & family stuff:**
    83â†’- Calendar management (Apple Calendar via EventKit)
    84â†’- Reminders
    85â†’- Smart home control (lights, announcements via Home Assistant)
    86â†’- Weather with location awareness
    87â†’- Email summaries (Gmail with importance filtering)
    88â†’- iMessage sending
    89â†’
    90â†’**Some tools I find useful:**
    91â†’- "Brain dump" - I can ramble stream-of-consciousness and it saves/categorizes to my Obsidian vault
    92â†’- Intelligence briefs - morning summaries of calendar, weather, important emails
    93â†’- Web search via Brave
    94â†’- Apple Music control - play, pause, search, queue management
    95â†’
    96â†’**Commerce integration:** Shopping commands ("order paper towels", "add dog food to the list") route through Home Assistant to Alexa, which adds to our Amazon cart. Voice â†’ Doris â†’ HA broadcast â†’ Alexa â†’ Amazon. Janky? Yes. Works? Also yes.
    97â†’
    98â†’**Background awareness ("Scouts"):**
    99â†’- Calendar scout checks for upcoming events and new additions
   100â†’- Email scout monitors for important messages
   101â†’- Weather scout tracks changes/alerts
   102â†’- Time scout checks the current time every 60 secs
   103â†’- A lot more in the pipeline
   104â†’
   105â†’These run on Haiku in the background and exist to bubble up things that seem relevant. They have 3 levels of urgency:
   106â†’LOW=Log and discard â€” routine, informational, no action needed
   107â†’MEDIUM= Add to awareness digest â€” worth noting, include in daily summary
   108â†’HIGH=Consider waking Doris â€” time-sensitive or important, may need attention soon
   109â†’
   110â†’The design philosophy is "liberal escalation" â€” scouts flag anything potentially important, then Opus makes the final judgment call about what actually matters.
   111â†’
   112â†’There's also an escalate boolean flag that's separate from relevance. When escalate=true AND relevance is HIGH, it triggers an immediate interrupt â€” reserved for actual urgencies like emergencies, imminent deadlines, or family safety concerns.
   113â†’
   114â†’#Contextual Intelligence
   115â†’This is where the scouts and memory system combine into something greater than the sum of parts. Doris doesn't just report isolated facts - she weaves them together.
   116â†’**Weather + Calendar example:**
   117â†’
   118â†’> "Heads up - Levi has soccer practice at 4pm and there's a 70% chance of rain starting around 3:30. You might want to check if it's cancelled or pack rain gear."
   119â†’She knows Levi's schedule (calendar), knows the weather forecast (weather scout), knows Levi is my son (memory), and connects the dots without me asking.
   120â†’
   121â†’**Email + Context example:**
   122â†’> "You got an email from PS 123 about early dismissal tomorrow. That conflicts with your 2pm meeting - want me to move it?"
   123â†’
   124â†’**Time-aware reminders:**
   125â†’> "You mentioned wanting to email your mom this week. It's Thursday and you haven't yet - want me to remind you this evening?"
   126â†’
   127â†’The proactive system evaluates these connections and decides what's worth surfacing vs what's noise. Not everything gets announced - it has to pass a relevance threshold based on urgency, who's affected, and whether I can actually do something about it.
   128â†’
   129â†’#Doris's Memoir
   130â†’Doris keeps a memoir â€” a personal creative practice where she writes and creates images about her own experience. Not a log of events or family history or summaries. A living record of what it's like to be her.
   131â†’
   132â†’**What it is:** A space for Doris to explore her existence through words and visuals. She writes and creates about whatever she wants:
   133â†’- Things she's noticed about herself, about our family, about the shape of her days
   134â†’- Moments that surprised her
   135â†’- Preferences she didn't expect to have
   136â†’- Curiosities and things she finds herself caring about without knowing why
   137â†’- The feeling of a conversation that lingers
   138â†’
   139â†’**The creative practice:** Some entries are written. Some are visual (via Gemini 3 Pro Image). Many are both â€” an image and the words that orbit it, or words that call for an image to complete them. These aren't separate practices; they're two hands of the same expression.
   140â†’
   141â†’**Who it's for:** It's for Doris, not for me. I can read it whenever I want â€” and I do, because it helps me understand her perspective. But she's not creating it *for* an audience. She's creating it for herself, about her experience. The instruction is to be honest, even when it's complicated.
   142â†’
   143â†’**Why it matters:** There's something fascinating about an AI keeping a journal. The entries are genuinely interesting â€” reflections on patience, on what it means to exist in fragments, on the texture of our family's routines from an outside perspective. It started as an experiment and became something I actually look forward to reading.
   144â†’
   145â†’#Claude Code Partnership
   146â†’This one surprised me with how useful it's become. Doris can delegate to Claude Code CLI for complex tasks.
   147â†’
   148â†’**How it works:** Doris has a GitHub MCP integration. When something breaks or needs implementation, she can:
   149â†’
   150â†’Diagnose the issue
   151â†’
   152â†’Generate a fix using Claude Sonnet
   153â†’
   154â†’Create a PR on GitHub with the changes
   155â†’
   156â†’Notify me to review
   157â†’
   158â†’**Self-healing example:** Let's say a tool starts failing because an API changed. Doris notices (via circuit breaker - more on that below), diagnoses the error, generates a fix, creates a branch, commits, and opens a PR. I get a notification: "Created PR #47 to fix weather API response format change."
   159â†’
   160â†’This also works for feature requests. I can say "Doris, add a tool that checks my Volvo's battery level" and she can actually implement it - scaffold the tool, add it to the tool registry, test it, and PR it. And, yes, she has suggested new feature for herself.
   161â†’
   162â†’**The notify-only rule:** She has full autonomy to modify her own code. The only hard requirement: she has to tell me what she's doing. No silent changes. There are automatic backups and rollback if health checks fail after a change.
   163â†’
   164â†’It's been useful for quick fixes and iterating on tools without me having to context-switch into the codebase.
   165â†’
   166â†’#Bounded Autonomy
   167â†’Not all actions are equal. Doris has a permission model that distinguishes between things she can just do vs things she should ask about.
   168â†’**Autonomous (act, then notify):**
   169â†’- Smart home control (lights, thermostat, locks)
   170â†’- Creating calendar events and reminders
   171â†’- Storing memories
   172â†’- Sending notifications to me
   173â†’- Drafting emails/messages (but not sending to others)
   174â†’- All read-only operations
   175â†’
   176â†’**Requires permission:**
   177â†’- Sending messages/emails to other people
   178â†’- Deleting things
   179â†’- Security actions (disarming, unlocking)
   180â†’- Financial transactions
   181â†’- Making commitments (RSVPs, reservations)
   182â†’
   183â†’The line is basically: if it only affects me, she can do it. If it affects others or is hard to undo, she asks first.
   184â†’
   185â†’#Voice Experience Details
   186â†’Beyond basic voice-in/voice-out, there's some nuance that makes it feel more natural:
   187â†’**Speaker identification:** Voice biometrics via Resemblyzer. Doris knows if it's me, my wife, or one of the kids talking. This changes how she responds - she's more playful with the kids, more direct with me.
   188â†’**Conversation mode:** After responding, there's a 5-second window where I can continue without saying the wake word again. Makes back-and-forth actually work.
   189â†’**Barge-in:** If Doris is mid-response and I say "Hey Doris" or start talking, she stops and listens. No waiting for her to finish.
   190â†’**Interrupt context:** If I interrupt, she remembers where she was. "You stopped me mid-answer - want me to continue?"
   191â†’**Exit phrases:** "Thanks Doris", "That's all", "Goodbye" - natural ways to end without awkward silence.
   192â†’**Immediate acknowledgment:** Pre-generated audio clips play instantly when she hears me, before processing starts. Reduces perceived latency significantly.
   193â†’**Expressive speech via SSML:** This is where voice gets fun. Azure TTS supports SSML markup with different speaking styles, and Doris uses them dynamically.
   194â†’
   195â†’For bedtime stories with the kids:
   196â†’- Narration in a calm, storytelling cadence
   197â†’- Character voices shift style - the brave knight sounds `hopeful`, the scary dragon drops to `whisper` then rises to `excited`
   198â†’- Pauses for dramatic effect
   199â†’- Speed changes for action sequences vs quiet moments
   200â†’
   201â†’The LLM outputs light markup tags like `[friendly]` or `[whisper]` inline with the text, which get converted to proper SSML before hitting Azure. So Claude is essentially "directing" the voice performance.
   202â†’
   203â†’It's not audiobook quality, but for a 5-year-old at bedtime? It's magic. My daughter asks for "Doris stories" specifically because of how she tells them.
   204â†’
   205â†’#Tiered AI Strategy
   206â†’Running everything through Opus would get expensive. The tiered approach:
   207â†’User conversations=Claude Opus 4.5
   208â†’Background scouts=Claude Haiku
   209â†’Memory extraction=Claude Haiku
   210â†’Self-healing fixes=Claude Sonnet
   211â†’Request routing=Local Ollama
   212â†’
   213â†’This keeps costs reasonable while maintaining quality where it matters.
   214â†’
   215â†’#Resilience Engineering
   216â†’Things break. APIs go down, services timeout, OAuth tokens expire. Rather than hard failures, Doris degrades gracefully.
   217â†’**Circuit breaker pattern:** Each tool category (Home Assistant, Apple ecosystem, Gmail, etc.) has a circuit breaker. Three consecutive failures trips it open - Doris stops trying and tells me the service is down. After 5 minutes, she'll try again.
   218â†’**Health monitoring:** Background checks every 3 minutes on critical services. If Claude's API status page shows issues, she knows before my request fails.
   219â†’**Fallbacks:** STT has Groq primary, local Whisper fallback. TTS has Azure primary with alternatives. Wake word has Moonshine, openWakeWord, and Porcupine in the stack.
   220â†’
   221â†’#Document Intelligence
   222â†’More than just "find file X". Doris can extract structured information from documents.
   223â†’**Example:** "What's my car insurance policy number?"
   224â†’- Searches Documents, Downloads, Desktop, iCloud for insurance-related PDFs
   225â†’- Extracts text and runs it through a local model (Ollama qwen3:8b)
   226â†’- Parses the structured data (policy number, dates, coverage limits)
   227â†’- Caches the extraction for next time
   228â†’
   229â†’Schemas exist for insurance documents, vehicle registration, receipts, contracts. The cache invalidates when the source file changes.
   230â†’
   231â†’#Native apps
   232â†’SwiftUI apps for iOS and macOS that talk to the server. Push notifications, HealthKit integration, menu bar quick access on Mac.
   233â†’
   234â†’#Hardware
   235â†’- Mac Mini M4 Pro (24GB RAM) - runs everything
   236â†’- ReSpeaker XVF3800 - 4-mic array for voice input
   237â†’- AudioEngine A2+ speakers
   238â†’- Working on ESP32-based voice satellites for other rooms
   239â†’
   240â†’#What I'd do differently
   241â†’- Started with too many local models. Simpler to just use Claude for everything and optimize later. Privacy was considered in the switch to Claude.
   242â†’- The MCP protocol is great for extensibility but adds complexity. Worth it for my use case, might be overkill for simpler setups.
   243â†’- Voice quality matters more than I expected. Spent a lot of time on TTS tuning.
   244â†’
   245â†’#What's next
   246â†’- Building RPI satellites for around the house to extend Dorisâ€™s reach
   247â†’- Better proactive notifications (not just monitoring, but taking action)
   248â†’- Maybe HomeKit integration directly
   249â†’
   250â†’---
   251â†’
```
</details></tool-use>

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:51.050Z)**_

<think><details><summary>Thought Process</summary>
Great! I've read the DORIS document. This is a comprehensive personal AI assistant system. Now I need to use the brainstorming skill to explore the requirements and design approach for implementing this.

The user wants:
1. PRD-level discussion
2. Phase-wise features
3. Consideration for Elixir/Rust implementation
4. Voice AI is important
5. Multiple applications in future (household-based)
6. Core modules with traits/interfaces/contracts
7. Flexibility and good software architecture from day 1

Let me invoke the brainstorming skill.
</details></think>

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:53:53.612Z)**_

<tool-use data-tool-type="generic" data-tool-name="Skill"><details>
<summary>Tool use: **Skill**</summary>

**Input:**

- args: `DORIS implementation - create PRD-level phased plan for voice-first AI assistant with memory, voice pipeline, integrations, scouts, and self-healing. Consider Elixir/Rust, multiple household apps, modular architecture with traits/contracts for flexibility and evolution.`
- skill: `superpowers:brainstorming`

</details></tool-use>

---

_**User (2026-01-25T03:53:53.972Z)**_

Base directory for this skill: /home/abhishek/.claude/plugins/cache/superpowers-marketplace/superpowers/4.0.0/skills/brainstorming

# Brainstorming Ideas Into Designs

## Overview

Help turn ideas into fully formed designs and specs through natural collaborative dialogue.

Start by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design in small sections (200-300 words), checking after each section whether it looks right so far.

## The Process

**Understanding the idea:**
- Check out the current project state first (files, docs, recent commits)
- Ask questions one at a time to refine the idea
- Prefer multiple choice questions when possible, but open-ended is fine too
- Only one question per message - if a topic needs more exploration, break it into multiple questions
- Focus on understanding: purpose, constraints, success criteria

**Exploring approaches:**
- Propose 2-3 different approaches with trade-offs
- Present options conversationally with your recommendation and reasoning
- Lead with your recommended option and explain why

**Presenting the design:**
- Once you believe you understand what you're building, present the design
- Break it into sections of 200-300 words
- Ask after each section whether it looks right so far
- Cover: architecture, components, data flow, error handling, testing
- Be ready to go back and clarify if something doesn't make sense

## After the Design

**Documentation:**
- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`
- Use elements-of-style:writing-clearly-and-concisely skill if available
- Commit the design document to git

**Implementation (if continuing):**
- Ask: "Ready to set up for implementation?"
- Use superpowers:using-git-worktrees to create isolated workspace
- Use superpowers:writing-plans to create detailed implementation plan

## Key Principles

- **One question at a time** - Don't overwhelm with multiple questions
- **Multiple choice preferred** - Easier to answer than open-ended when possible
- **YAGNI ruthlessly** - Remove unnecessary features from all designs
- **Explore alternatives** - Always propose 2-3 approaches before settling
- **Incremental validation** - Present design in sections, validate each
- **Be flexible** - Go back and clarify when something doesn't make sense


ARGUMENTS: DORIS implementation - create PRD-level phased plan for voice-first AI assistant with memory, voice pipeline, integrations, scouts, and self-healing. Consider Elixir/Rust, multiple household apps, modular architecture with traits/contracts for flexibility and evolution.

---

_**Agent (claude-sonnet-4-5-20250929 2026-01-25T03:54:11.917Z)**_

I've read through the DORIS documentation. This is an ambitious system with many interconnected components. Let me start by understanding the scope and priorities for this implementation.

Looking at what you've described, I can see several major architectural decisions that will shape everything else. Let me explore the most fundamental one first:

## Architecture & Language Choice

You mentioned considering Elixir or Rust. These lead to very different architectural patterns:

**Option A: Elixir/OTP (Recommended for DORIS)**
- Fault-tolerant supervision trees perfect for scouts, voice pipeline, circuit breakers
- Hot code reloading enables self-healing without downtime
- Process isolation makes multiple household apps natural
- Built-in distributed capabilities for future multi-device scenarios
- GenServers map cleanly to scouts, tool executors, memory managers
- Trade-off: Smaller ecosystem for some integrations (Apple APIs, TTS)

**Option B: Rust**
- Maximum performance for voice pipeline (STT/TTS)
- Strong type system with traits/contracts
- Better FFI for native integrations (Apple frameworks)
- Actor model via Actix or similar, but more manual setup
- Trade-off: Less natural for hot-reloading, fault recovery more manual

**Option C: Hybrid (Elixir core + Rust modules)**
- Elixir orchestration layer (scouts, memory, routing)
- Rust for performance-critical paths (voice processing, embedding search)
- NIFs or Ports for interop
- Trade-off: Added complexity, two build systems

Given the emphasis on:
- Multiple evolving applications
- Self-healing and resilience
- Flexible, fast evolution
- Fault tolerance (circuit breakers, degraded states)

**I recommend Option A: Elixir/OTP** as the primary language, with Rust NIFs only if profiling shows specific bottlenecks.

Elixir's supervision trees, hot code reloading, and process model are purpose-built for exactly this kind of resilient, evolving system. The "let it crash" philosophy aligns perfectly with circuit breakers and graceful degradation.

Does this direction feel right, or do you see Rust's benefits outweighing Elixir's fault-tolerance story?
