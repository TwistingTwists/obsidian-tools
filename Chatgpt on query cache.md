 I will research the latest versions of Elasticsearch, GreptimeDB, InfluxDB, and Quickwit. I'll focus on:

- Full technical analysis of their query cache mechanisms (architecture, algorithms, cache invalidation, memory management, etc.)
    
- Distributed cache behavior (partitioning, coherence, warming, admission control, metrics)
    
- Deep interactions between query cache and query planner (including partial caching, Bloom filters, aggregation handling)
    
- Special handling for observability-specific challenges (high-cardinality, time-series patterns, recent vs. historical data)
    
- Detailed codebase references: pointing to actual files, classes, and functions
    
- Relevant technical blog posts, documentation, or papers if available
    
- A structured write-up: detailed sections per system, followed by a comprehensive comparison across all dimensions
    

I'll get started and will update you once the deep research is ready!

# Elasticsearch Query Caching

Elasticsearch provides two primary query-related caches: the **node query cache** (often called the “filter cache”) and the **shard request cache**. The node query cache (implemented by the `IndicesQueryCache` class) holds bitset filters that can be reused across queries. It is **per-node** (shared by all shards on that node) and stores Lucene-level bitsets for “filter” clauses ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=Elasticsearch%20features%20a%20IndicesQueryCache%20class,takes%20up%20two%20configuration%20options)) ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=development%3F)). By default it can use up to ~10% of the heap and 10,000 entries (configurable via `indices.queries.cache.size` and `.count`) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010)). Internally it uses Lucene’s `LRUQueryCache` (wrapping roaring bitmaps) with an LRU eviction policy, only caching filters on segments ≥10k docs and ≥3% of shard docs ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=public%20LRUQueryCache,03f%29%2C%20250%29%3B)) ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=filters%20are%20quite%20fast%20to,total%20documents%2C%20whichever%20is%20larger)). Elasticsearch also tracks filter frequencies (via a `UsageTrackingQueryCachingPolicy`) so that only frequently-used filters are cached ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=However%2C%20things%20are%20a%20little,the%20minimum%20frequency%20to%20be)). The **shard request cache** (`IndicesRequestCache`) stores entire search responses (bytes) keyed by the query and segment reader. It is **per-index (per-shard)** and caches results of complete search requests, typically those with `size=0` (aggregation-only) by default ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20component%20responsible%20for%20caching,to%20avoid%20skewing%20the%20results)) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=IndicesRequestCache%28Settings%20settings%29%20)). The request cache uses a weight-based `CacheBuilder` (by default limited to a percentage of heap via `indices.requests.cache.size`) and can expire entries after an access TTL ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)). Both caches expose metrics (`_nodes/stats/indices/query_cache` and `indices/request_cache`) for hit/miss rates ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition,rates%20and%20other%20information%20via)).

**Data structures & algorithms:** The query cache uses bitsets (one per segment-filter) stored in JVM heap. It builds Roaring bitmaps (Lucene’s `DocIdSet`) that mark matching documents for a filter range ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=So%2C%20how%20can%20this%20be,set%20would%20look%20like%20this)) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=So%2C%20how%20is%20this%20implemented,Lucene%3F%20Let%E2%80%99s%20take%20a%20look)). Combining filters uses bitmap operations, allowing fast reuse. The request cache keys on a composite of index+reader+query and stores raw serialized hits (as `BytesReference` blobs) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)). Both caches use LRU eviction by default. Configurables allow limiting by entry count and memory. The query cache can optionally evict entries based on access time (via `indices.queries.cache.all_segments` and expire settings) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010)). Notably, Lucene’s `MinSegmentSizePredicate` avoids caching very small or large segments below thresholds ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=public%20LRUQueryCache,03f%29%2C%20250%29%3B)), balancing overhead vs benefit.

**Invalidation:** Elasticsearch invalidates caches on index changes. The query cache entries are keyed by segment “core key,” so when a segment merges or a new one opens, its cache entries become invalid (new segment = new key) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=the%20existing%20ways%20to%20query,set%20needs%20to%20be%20created)). The request cache is invalidated on every shard refresh or mapping change – fresh writes automatically clear cached results to prevent staleness ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=filter%20context%20are%20used%20to,total%20documents%2C%20whichever%20is%20larger)). Thus caches only serve unchanged data. Because data streams/time-based indices are append-only, older indices stay cacheable until their shards refresh.

**Memory management:** Both caches count usage in JVM heap bytes. The IndicesQueryCache monitors `sharedRamBytesUsed` and reports per-shard stats ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesQueryCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesQueryCache.java#:~:text=private%20final%20Map,new%20ConcurrentHashMap)). The IndicesRequestCache uses a weighted LRU (weigher accounts for key + value memory) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)). Administrators can set e.g. `indices.queries.cache.size` (percent of heap) and `indices.requests.cache.size` (absolute bytes or percent) to tune usage. If caches fill, LRU eviction purges the least-recently-used bitsets or entries.

**Performance optimizations:** Elasticsearch can rewrite queries for cacheability. For example, time-based filters on a data stream can be rewritten to a `match_all` for older indices (if all documents fall in the filter range) so that identical queries hit the request cache ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20second%20visualization%20is%20very,000004)) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20component%20responsible%20for%20caching,queries%20that%20are%20being%20profiled)). The query cache’s frequency tracking ensures only hot filters occupy heap. Because it caches at the bitset (postings) level, subsequent queries with different match-clauses but identical filter bitsets need not read disk again – they reuse cached bitmaps ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=So%2C%20how%20can%20this%20be,set%20would%20look%20like%20this)). Shard request caching can also store whole aggregation results, eliminating the need to rerun aggregations on data that didn’t change ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20component%20responsible%20for%20caching,to%20avoid%20skewing%20the%20results)).

**Configurable parameters:** Key settings include `indices.queries.cache.size/count` (node-level query cache limits) and index-level `index.requests.cache.enabled/expire` (shard request cache on/off and expiration) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010)) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=if%20%28expire%20%21%3D%20null%29%20)). By default, the request cache only caches queries with no hits (primarily aggregations), but this can be overridden per-request or per-index. Fielddata and doc-value caches (for aggregations on fields) are separate and also tunable, though they serve different roles.

**Trade-offs:** Query caching trades heap usage against query latency. The IndicesQueryCache can consume significant heap (10% by default) to store bitmaps, which speeds up repeated filter-heavy queries but costs memory that could be used elsewhere. Because bitsets are regenerated on segment changes, frequent merges (in high-write scenarios) can incur overhead clearing caches. The request cache avoids IO only if data hasn’t changed; long refresh intervals keep cache entries valid but delay query visibility. Enabling query caches for “almost all” queries (beyond filter contexts) can hurt performance, so ES restricts caching to deterministic filters by default. Choosing cache sizes involves balancing hit-rate vs memory overhead. Elasticsearch’s design keeps caches always consistent (no stale data), ensuring correctness at the cost of re-computation after writes.

**Distributed considerations:** In a cluster, each node manages its own caches independently. There is **no global cache coherence protocol** – each shard’s query cache or request cache lives locally on its node. This means a query hitting different shards will only reuse cache entries per-shard; filters common across shards will each build their own bitsets. Cache partitioning naturally follows shard distribution. The system does **not** synchronize or replicate cache entries, but it does use coordination for query routing: for example, the coordinator might use rendezvous hashing or index routing so that identical queries often hit the same node/shard pair and benefit from local caching. After a node joins or restarts, caches must **warm up** from scratch; Elasticsearch does not pre-load query caches on node failure recovery (other than via normal querying). There is no explicit query admission control beyond configuration; if memory pressure is high, the built-in LRU eviction simply rejects new entries by evicting old ones. Elasticsearch exports cache hit/miss stats via the `_nodes/stats/indices/query_cache` and `request_cache` APIs ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition,rates%20and%20other%20information%20via)) ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=Elasticsearch%20gives%20a%20number%20of,the%20above%20in%20one%20call)), which can be monitored. Eviction is primarily space-based (LRU by weight) but can also use time-based expiration if configured (`expireAfterAccess`). Multi-tenant setups (e.g. multiple indices for different users) share the same cache pool, so “noisy” tenants can evict others’ entries – ES does not isolate caches per user. In balancing freshness vs latency, Elasticsearch opts for **strict consistency**: caches are invalidated on every write-refresh, so queries always see up-to-date data, even if that means losing cache hits. There is no adaptive heuristics beyond the frequency tracking policy; however, caching effectively gives higher priority (in memory) to _hot_ filters, since cold filters will be evicted.

**Query execution interaction:** Elasticsearch’s query planner applies caching mostly transparently. Filter clauses (e.g. range or term filters) that qualify are fed through the query cache. The planner may rewrite filter expressions into simpler forms (like match_all) when safe ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20second%20visualization%20is%20very,000004)), increasing cache hits. Partial result caching (caching only part of a query) is not a user-facing feature, though internally filters can be cached independently of full query context. Aggregation queries (with `size=0`) are prime candidates for the request cache, whereas queries fetching raw hits typically bypass the cache unless explicitly requested. There is no Bloom filter at the cache level (Lucene does use per-block index and min/max summaries internally, but ES does not expose bloom filters for cache). Complex join operations (e.g. parent/child) are generally not cached; only individual filter results or entire search results are cached.

**Observability concerns:** Elastic’s caching is less effective on extremely high-cardinality tag queries, since very selective term filters produce small bitsets and are often cheap without caching (the caching policy even avoids one-hit filters ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=FrequencyTrackingRingBuffer%20%28implemented%20using%20fixed,the%20minimum%20frequency%20to%20be))). In logs use cases, time-based filters can be effectively cached if the query segments align with index partitions. For time-series queries (typical in observability dashboards), rewriting constant time ranges to `match_all` on certain indices can make multiple queries identical and thus cacheable ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20second%20visualization%20is%20very,000004)). Recent vs. historical data is implicitly managed: recent segments get frequent indexing, causing merges and refreshes that flush caches; older indices seldom change, so their filters remain cached and can be quickly reused. In practice, queries on “hot” (recent) data benefit from the in-memory file system cache and doc-values, whereas queries on “cold” data rely on the query/request caches for speed. Elasticsearch provides statistics and per-index cache clearing APIs to tune behavior for observability workloads.

# GreptimeDB Query Caching

GreptimeDB uses a **multi-tier caching architecture** tailored for time-series workloads. Incoming writes first go to a write-ahead log (WAL) and an in-memory **Memtable**. Flushes convert Memtable data to columnar Parquet files, which are written both to remote object storage (S3) and to a local **Write Cache**. The write cache is a **write-through** layer of on-disk files that holds _recent_ time-series data (configurable by size or TTL). For historical data reads, Greptime employs a **Read Cache**: a local disk-based store caching Parquet data pages with an LRU eviction policy ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache)) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=match%20at%20L178%201,series%20query%20patterns)). In effect, Greptime mimics an OS page cache – newly accessed Parquet pages (or ranges of rows) are stored locally so that future queries on the same time ranges or tags can avoid fetching from object storage ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=match%20at%20L178%201,series%20query%20patterns)). Metadata and index structures (table schemas, routing, Parquet file metadata, SST metadata) are also cached in memory/disk to speed up planning.

**Data structures & algorithms:** Greptime’s write and read caches use simple LRU lists (recently used pages/files stay, evict oldest). Originally a custom LRU crate was used, but recent versions use the Rust `moka` cache library for concurrency and efficiency ([feat: improve object storage cache by killme2008 · Pull Request #2522 · GreptimeTeam/greptimedb · GitHub](https://github.com/GreptimeTeam/greptimedb/pull/2522#:~:text=,to%20remove%20the%20evicted%20files)). The cache keys are typically file-path or page-range identifiers, and values are raw Parquet page bytes. The write cache writes new Parquet files to a local directory (size-based or TTL constraints), ensuring that fresh data is immediately queryable from local disk rather than waiting for object storage ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=,Write%20Cache%20and%20object%20storage)) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=3,low%20latency%2C%20bypassing%20object%20storage)). The read cache pulls older Parquet data pages into a local cache (up to a configured capacity, default 5GiB) ([Configuration | GreptimeDB Documentation](https://docs.greptime.com/user-guide/deployments/configuration#:~:text=GreptimeDB%20provides%20a%20local%20cache,speed%20up%20repeated%20data%20access)). Eviction is based on either total size (newer merged PR [28†L1-L4] changed from counting entries to actual byte weight) or on-write TTL for the write cache. Cached entries are expunged on eviction (files deleted) via `async_eviction_listener` ([feat: improve object storage cache by killme2008 · Pull Request #2522 · GreptimeTeam/greptimedb · GitHub](https://github.com/GreptimeTeam/greptimedb/pull/2522#:~:text=,to%20remove%20the%20evicted%20files)).

**Invalidation:** Since Greptime treats the cache as a filesystem-based store, invalidation occurs naturally: if a Parquet file is overwritten by a newer flush or TTL expires, its cache entry is dropped. The write cache may have a TTL per file (configurable) after which it is evicted ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=match%20at%20L160%20,TTL%20of%20the%20cached%20files)). Unlike a query-result cache, Greptime’s caches don’t need complex coherence – they simply hold data pages that are immutable. If underlying data changes (e.g. a partition rollover or retention drop), the corresponding cache files are invalidated or never accessed. There is no separate “query cache key” to invalidate; the cache is warmed by actual data access patterns.

**Memory and storage management:** Greptime’s caches primarily use _disk space_ for capacity, with some in-memory indexing. By default, both read and write cache capacities are 5 GiB each ([Configuration | GreptimeDB Documentation](https://docs.greptime.com/user-guide/deployments/configuration#:~:text=GreptimeDB%20provides%20a%20local%20cache,speed%20up%20repeated%20data%20access)). The system exposes metrics (`greptime_mito_cache_bytes`, `greptime_mito_cache_hit/miss`) for monitoring cache usage ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss)). Administrators tune cache sizes based on query patterns; e.g. large high-cardinality queries may require more cache to hold relevant pages. Because the cache is file-backed, it avoids pinning heap, but it does consume local SSD. The design deliberately trades local disk usage for drastically lower latency than pulling from remote storage ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache)). There’s also an in-memory Memtable and optional in-memory WAL cache, so memory usage is configurable via Write-Ahead Log and Memtable settings, distinct from the cache.

**Performance optimizations:** Greptime’s cache optimizations are workload-aware. It organizes data by time partitions, so recent queries usually hit the in-memory Memtable or the write cache (bypassing object I/O entirely) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=,millisecond%20query%20latency)). For warm/historical queries, the read cache uses an LRU policy so that frequently-accessed pages remain local. Greptime can also **prefetch** ranges: the blog mentions proactive prefetching into read caches to speed up expected scans ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=,read%20caches%20for%20optimized%20performance)). Compression and columnar encoding (Parquet) further optimize I/O per query. Additionally, Greptime’s LSM engine can mark cold data at merge time, reducing fragmentation and keeping “hot” data in cache-friendly layout.

**Configurable parameters:** Key settings include enabling/disabling the read and write caches and their capacities. For example, in the storage engine config one can set `cache_capacity` and `write_cache_size` ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=match%20at%20L132%20,total%20disk%20space%20for%20it)) ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=,value%20for%20this%20cache%20is)). There are also TTL settings (`experimental_write_cache_ttl`) so write cache files auto-expire ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=match%20at%20L160%20,TTL%20of%20the%20cached%20files)). Metrics (`greptime_mito_cache_*`) allow tuning: if misses are high, increase cache size ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=You%20can%20monitor%20the%20,label%20in)). The underlying implementation recently switched to using byte-based limits (via moka) rather than entry counts ([feat: improve object storage cache by killme2008 · Pull Request #2522 · GreptimeTeam/greptimedb · GitHub](https://github.com/GreptimeTeam/greptimedb/pull/2522#:~:text=,to%20remove%20the%20evicted%20files)).

**Design trade-offs:** Greptime’s design favors **throughput and low-latency on recent data**. By caching newly written segments and reading from local disk, it avoids latency of object storage. The trade-off is extra disk usage and complexity in managing a hybrid storage tier. Write cache (write-through) ensures durability while speeding reads, but it must be sized correctly to avoid running out of disk. Evicting based on age (TTL) ensures freshness vs space. Using an on-disk cache rather than pure in-memory means misses incur an SSD read rather than an object fetch; this is much faster, but still slower than RAM. Compared to a pure in-memory query result cache, Greptime’s caches are coarser (pages of data, not specific query results) but scale to larger dataset sizes with less RAM.

**Distributed query caching:** In clustered deployments, each Greptime node maintains its own caches – there is **no global cache replication**. Shards are assigned to nodes, and that node’s cache serves its queries. The cluster uses etcd-backed metadata to route queries, but cache data is local. On node failure or addition, the new node’s caches start empty; “cache warming” happens naturally as queries hit it. Greptime does not appear to implement special warm-up protocols; instead, metrics-level (like dropping in `greptime_mito_cache_hit`) will show cold-start performance. There is no explicit coordination for cache coherence; the system relies on the fact that caches hold immutable pages, so there is no need for coherence protocols. Under memory/disk pressure, the LRU mechanisms in moka will evict least-recently-used pages. There is no documented scheme for prioritizing “hot” versus “cold” queries other than the inherent LRU policy – queries that repeatedly touch the same pages effectively keep those pages in cache. Metrics expose hit/miss counts for diagnosing effectiveness ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss)). Eviction is purely space-based (LRU by byte size) rather than time-based (apart from TTL on write cache). Greptime’s caches are not multi-tenant aware; all tables on a node share the same cache pool. Greptime emphasizes freshness for new data (because writes go to cache immediately) and does not serve stale data: the write cache files are truncated once data is successfully pushed to object storage ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=1.%20WAL%20%28Write)).

**Interaction with query execution:** Greptime’s caching is largely transparent to the query planner: the planner simply reads data pages, and the storage engine fetches from cache if available. Partial-result caching (caching intermediate query results) is not explicitly implemented; rather, caching is at the data-page level. Aggregations versus raw lookups both benefit: aggregations will read the needed pages (perhaps from cache), and the engine will merge Memtable (recent inserts) with cached/read Parquet data. There’s no specialized Bloom filter at the cache layer – caching is page-based. Complex joins or nested queries (if any, though Greptime is mainly TSDB) would likewise benefit from cached pages.

**Observability-specific concerns:** Greptime is optimized for time-series patterns. High-cardinality tag dimensions are handled by storing data in wide columnar format and using compressed Parquet; the cache does not index by tags, so a highly selective tag query still reads column pages (which can come from cache). Because caches hold raw data pages, cardinality mainly affects compression ratio and I/O rather than cache design. Greptime explicitly differentiates recent vs historical: recent data is always found in Memtable or write cache, giving sub-millisecond latency ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=3,low%20latency%2C%20bypassing%20object%20storage)), whereas older data may require fetching from object storage if not cached. The cache warms up over time – an upgrade or cluster restart may see a transient period of higher latency until common pages load into the read cache ([Frequently Asked Questions | GreptimeDB Documentation](https://docs.greptime.com/0.9/faq-and-others/faq/#:~:text=Frequently%20Asked%20Questions%20,query%20performance%20after%20an%20upgrade)). Overall, Greptime’s caching strategy is time-aware: it expects queries that frequently cover recent time windows to hit the write cache, and query patterns that repeatedly scan similar historical ranges to hit the read cache.

# InfluxDB Query Caching

InfluxDB’s caching is centered on its **time-structured merge tree (TSM)** storage engine and TS index. The in-memory **cache** in InfluxDB is an on-heap store of recent writes (pre-TSM): every write goes into a WAL and also into this memory cache ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=Cache)). Once the cache grows beyond `storage-cache-max-memory-size`, it is snapshot to disk (TSM) or flushed on write inactivity ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). Thus, **recent points** are quickly queryable from memory. Influx also maintains an internal cache for the Time Series Index (TSI): the `storage-series-id-set-cache-size` parameter (default 100) controls a cache that maps tag-value predicates to the set of matching series IDs ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). This _series-ID-set cache_ returns cached results for repeated tag-key/value filters, avoiding recalculating postings.

**Data structures & algorithms:** The primary query cache is effectively the _memtable_ cache of new points. It organizes points by series key (measurement+tags+field) and time, storing them uncompressed in memory ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=Cache)). On queries, the engine merges data from this cache with data from TSM files. For tag-index caching, TSI uses bitsets or simple ID lists under the hood, and Influx caches the combined result as a slice of IDs. (Each cache entry corresponds to a specific tag-key/value query.) Influx’s WAL/cache snapshot logic is LRU-like (snapshot older data out of memory when size grows) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). The series-id cache is a fixed-size LRU: it holds up to N recent predicates.

**Invalidation:** The in-memory cache naturally “invalidates” via flush: when a WAL file is compacted to a TSM file, its data has already been served and can be removed from cache or snapshotted ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=1,the%20write%20request%20was%20successful)). The series-id cache entries become stale if new points arrive that affect those series; Influx doesn’t appear to track invalidation per query, but because queries always merge current cache + TSM, a slight stale cache might miss some new series until next query. If consistency is required, one can disable the series-id cache (`series-id-set-cache-size=0`) or rely on the fact that new writes will eventually update the index in memory.

**Memory management:** The in-memory write cache is bounded by `storage-cache-max-memory-size` (default ~1GiB) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). Influx will snapshot (compress) when approaching this limit to free memory. The series-id cache size (default 100) is small (heap per entry depends on number of series). Influx also uses configurable index log WAL sizes to manage heap. There’s no separate “query cache” that holds full query results, so memory usage is mainly the write cache plus indexes. Large caches improve recent query latency but use more heap; conversely, small caches limit RAM but increase disk I/O. Influx does not expose cache hit counters in OSS, but one can infer the effectiveness from query latencies and WAL flush patterns.

**Performance optimizations:** By design, Influx’s memtable means queries on the very latest data (before TSM flush) are very fast. Long-range or historical queries must read TSM files; in those cases, Influx’s indexing (TSI) and series caches help skip irrelevant series. Influx can take “snapshots” of the cache to TSM when writes cease (`cache-snapshot-write-cold-duration`) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)) to free memory and speed future queries (by compacting). The series-id cache avoids repeated expensive series lookups for popular tag filters ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). Additionally, each TSM file contains built-in summary blocks (min/max timestamps, Bloom filters of series) that help skip scanning, but these are automatic and not user-adjustable in config.

**Configurable parameters:** Key settings include the memtable size (`storage-cache-max-memory-size`), the write-cold snapshot trigger (`storage-cache-snapshot-memory-size` and `write-cold-duration`) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)), and `storage-series-id-set-cache-size` for tag predicate caching ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). For TSI, one can also tune `tsi-max-memory-size` (total index memory) and WAL compaction thresholds. Changing these affects memory pressure: e.g. higher `series-id-set-cache-size` stores more query results at the cost of heap ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). Influx DB 3.0 introduces a “Last Value Cache” (LVC) feature for recent value queries (blog: _“InfluxDB 3 Last Value Cache”_), but this is a higher-level construct (an in-memory table) separate from core engine caching ([Query the Latest Values in Under 10ms with the InfluxDB 3 Last Value Cache | InfluxData](https://www.influxdata.com/blog/-influxdb3-last-value-cache/#:~:text=Note%3A%20Values%20are%20cached%20on,points%2C%20only%20newly%20written%20points)).

**Trade-offs:** Influx prioritizes ingestion and query speed for recent data. A large memtable cache speeds write-throughput and low-latency reads, but if unbounded, can exhaust RAM – hence the flush controls. The TSI series-ID cache trades memory for query speed on common tag filters; disabling it (size=0) can slow queries significantly ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=series%20results,and%20may%20decrease%20query%20performance)) but saves memory. Influx focuses on **strong consistency**: when writes occur, queries always reflect them (merging in-memory and TSM); there’s no use of stale results. It does not re-use full query results beyond this index cache, so repeated complex queries still re-scan data (except their tag components).

**Distributed considerations:** InfluxDB Enterprise (clustered) shards data across nodes, but each node has its own cache of recent writes and index results. There is no distributed cache coherence beyond data replication: each data node locally caches its WAL/memtable and series caches. If a node leaves or a cluster expands, its new nodes start with empty caches and will warm up as queries hit them. There are no explicit cross-node protocols for caching; each node independently flushes and caches. The series-id cache effectively partitions by database and retention policy, but is global within a node for all series. InfluxDB does not provide multi-tenant cache sharing; separate databases or orgs use separate shards/caches. Under memory pressure, Influx evicts by converting in-memory cache to disk (snapshots) – not by LRU replacement of data, since data is appended-only. Metrics can be gleaned from internal `_monitoring` system (e.g. WAL and index metrics), but Influx does not give built-in cache hit ratios to the user. Eviction is primarily time-based (snapshot after inactivity) and size-based (flush at threshold), not LRU. Because InfluxDB merges in-memory data on every read, it effectively values freshness over cached speed: even if a series-id entry is slightly stale due to recent writes, the query will still fetch new points from memtable.

**Query execution interaction:** The Influx query engine merges data from the in-memory cache and TSM at query time ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=Cache%20snapshots%20are%20cache%20objects,range%20for%20a%20specified%20key)). There is no separate planner-driven cache hinting. Continuous queries are recommended for pre-aggregating frequent queries (historically) rather than ad-hoc caching. For aggregation vs raw queries, InfluxDB 3.0’s Last Value Cache (LVC) can materialize latest values for fast “last” queries, but for InfluxDB 2.x it is absent. Bloom filters exist implicitly in TSM file blocks for series skipping, but users don’t tune them. Influx does not cache partial query results by default (e.g. sub-aggregation outputs), except that the series-id cache might serve repeated tag scans. Joins are not a core Influx feature (beyond some limited subquery constructs), so caching around joins is not relevant.

**Observability-specific concerns:** High-cardinality tag queries can stress Influx’s index: the series-ID cache may not be effective if most queries are unique or if cardinality far exceeds cache entries (default 100) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)). In that case, memory usage grows due to storing many series, and caching yields little benefit. The TSI index uses disk and OS page cache to handle cardinal data, but queries may slow. For typical time-series query patterns (time ranges, aggregations), Influx’s in-memory cache shines: queries on the latest data (within WAL/memtable) are very fast, often sub-millisecond. For older data, performance depends on TSM scanning. Influx does not explicitly treat “recent vs historical” in caching beyond that: fresh writes are in memory, older data is on disk. There's no separate caching for “hot” recent slices beyond the general write cache. One must size caches to handle the expected working set of recent points or tag filters.

# Quickwit Query Caching

Quickwit is a cloud-native search engine that shards data into **“splits”** (time-based index segments) stored on object storage. Its caching strategy is **hybrid** and multi-layered: at query time, Quickwit can cache _split footers_ (the “hotcache”), _fast fields_, _partial query results_, and even entire split files.

**Architecture:** Each Quickwit node (a **searcher**) fetches the needed splits for a query. A split file contains full-text index data and a footer of fast metadata. Quickwit’s **hotcache** is essentially the split footer: it contains posting lists and field dictionaries needed for text search and timestamp filtering. By caching footers in memory, Quickwit avoids re-reading them from object storage on every query ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G)). **Fast fields** (columnar indices, e.g. for timestamp or numeric tags) are also loaded and cached in memory on demand – this is the “fast field cache”, limited by `fast_field_cache_capacity` ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=2,1G)). Quickwit can additionally cache **partial results**: if two queries differ only by a time boundary, intermediate bitset filters can be reused (via `partial_request_cache_capacity`). Finally, Quickwit’s **split cache** (on local disk) can store entire split files to amortize object storage cost (LRU-evicted based on `max_num_bytes`) ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=,with%20a%20simple%20LRU%20strategy)) ([quickwit/config/quickwit.yaml at main · quickwit-oss/quickwit · GitHub](https://github.com/quickwit-oss/quickwit/blob/main/config/quickwit.yaml#:~:text=split_cache%3A)).

**Data structures & algorithms:** The hotcache is a map of split-ID to its footer data (likely Roaring bitmaps for posting lists, and doc-id mappings). Fast fields use columnar arrays and sometimes bitmaps (Roaring) for compressed values; these are cached by split and field. The partial cache stores intermediate `HashMap<QueryKey, BitSet>` states from one split. All caches are LRU/LFU by split and bounded by byte-size (e.g. split_footer_cache_capacity: 500 MB default ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G))). The split cache uses a disk-based LRU: when a split is first created or fetched, Quickwit stores its compressed file on a `split_store`. If the store is full, old splits are evicted (FIFO/LRU by time) ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=,with%20a%20simple%20LRU%20strategy)).

**Invalidation:** Splits in Quickwit are immutable once written (they represent a time slice of indexed data). Thus, cached entries remain valid indefinitely; there is no need to invalidate footers or fast fields for existing splits. If a split is merged or rolled over, that produces a new split ID; old entries become unreachable. The split cache evicts based on storage limits or TTL. Because data is static, Quickwit can safely assume cached pages are fresh.

**Memory management:** Quickwit’s hotcache and fast field caches are in-memory, limited by configuration. The default footer cache is 500 MB and fast-field 1 GB ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G)) ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=,accessed%20very%20frequently%20by%20users)). Metrics like `quickwit_cache_fastfields_cache` are exposed for tuning. These caches use contiguous memory (Rust structures) and are sized in bytes. Quickwit avoids putting the whole index in RAM; by default it only caches footers and needed fields. The split cache (on disk) is sized (e.g. 1 GB by default ([quickwit/config/quickwit.yaml at main · quickwit-oss/quickwit · GitHub](https://github.com/quickwit-oss/quickwit/blob/main/config/quickwit.yaml#:~:text=split_cache%3A))) and so uses SSD space, evicting whole splits as needed.

**Performance optimizations:** Caching dramatically cuts down object fetches. In a 23TB benchmark, fetching all split footers on each query entailed 715 GETs and 6.45 GB of data per query ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=Detailing%20the%20IO%20operations%20performed,by%20the%20searchers%20reveals)). By keeping these footers in memory, query latency falls off sharply (see chart below). Similarly, caching the timestamp fast-field column avoids re-downloading 13.4 GB on each query with many splits ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=Detailing%20the%20IO%20operations%20performed,by%20the%20searchers%20reveals)). Quickwit also uses **rendezvous hashing** when distributing queries to searchers: this pins each split to a particular searcher to maximize cache hits ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=1,and%20returns%20them%20to%20the)). Thus, repeated queries on the same time range go to the same node that holds the cache for those splits. The partial request cache can serve identical dashboard queries (varying only time) by slicing and caching filter bitsets, reducing redundant work. The default LRU eviction ensures that frequently-accessed splits stay cached across queries.

([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset)) _Quickwit benchmark: Without caching, query latency plateaus due to I/O (left panels). Caching split footers (“hotcache”) and fast fields drives latencies down dramatically (not shown), as illustrated by the improved curves in the source study ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=)) ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=))._

**Configurable parameters:** Node-level config includes `split_footer_cache_capacity` (hotcache size) and `fast_field_cache_capacity` ([Node configuration | Quickwit](https://quickwit.io/docs/configuration/node-config#:~:text=,can)). Also `partial_request_cache_capacity` and the split store settings (`split_cache.max_num_bytes/splits`) ([quickwit/config/quickwit.yaml at main · quickwit-oss/quickwit · GitHub](https://github.com/quickwit-oss/quickwit/blob/main/config/quickwit.yaml#:~:text=split_cache%3A)). Quickwit exposes metrics for these (e.g. `quickwit_cache_fastfields_cache{hits,misses}`) to aid sizing. A larger footer cache (beyond 500M) can hold more splits’ metadata, further reducing load. The split store size controls how many whole splits are kept on disk (e.g. SSD caching), balancing local I/O vs object storage costs.

**Trade-offs:** Quickwit’s design trades off memory and disk versus cloud I/O. Keeping an index’s metadata (footers, fields) in memory speeds queries, but RAM must be allocated accordingly. If these caches are too small, the engine will re-fetch data over the network. The on-disk split cache uses SSD to prefetch or buffer splits, reducing GET requests – this saves object storage bandwidth but uses local disk I/O. Crucially, Quickwit by default **does not** cache query results globally, because different queries often touch different splits or fields; instead it caches index data that is reusable. This means consistency is trivial (immutable splits) and no stale data issues arise. However, it also means each node must fetch the initial data once and cannot “share” across nodes; the rendezvous scheme mitigates this by locality.

**Distributed considerations:** Quickwit clusters distribute query work via shards called “splits.” Using rendezvous hashing, queries with a timestamp range and tag filters go to specific searchers that own those splits ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=1,and%20returns%20them%20to%20the)). Thus the cache is _partitioned by split_: each split’s footer and data are cached on one node. There is no global cache coherence protocol because splits are read-only. When a node fails or a new one joins, splits are redistributed and their caches must warm up (no automatic replication). The rendezvous hashing helps minimize such warm-up by keeping the same split on the same node as much as possible. Hot vs. cold queries are handled by the LRU caches: very frequent splits/fields stay in cache, while rarely queried splits get evicted first. Under memory pressure, Quickwit evicts based on its capacity settings (space-based). It exposes metrics (e.g. `quickwit_cache_...`) for monitoring cache hit rates. Quickwit’s caching is not multi-tenant; one cluster-level cache serves all queries on that cluster. In balancing freshness vs latency, Quickwit assumes stale data is not an issue (new data creates new splits). Thus it fully favors performance by keeping data cached as long as it fits, since caches never serve outdated content.

**Query execution interaction:** Caching in Quickwit is integrated into query planning and execution. The planner first identifies relevant splits by time and tags, then queries each split. If a split’s footer is cached, Quickwit can skip downloading it and directly use its bitsets to filter documents ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G)). Fast fields speed up aggregations or range scans (e.g. filtering by timestamp without decompression). The partial request cache stores intermediate bitset states for each split when queries only differ slightly, allowing reuse in dashboards. Joins or nested queries (if supported) would likely also leverage the same caches per split. There is no traditional SQL planner here; caching is transparent at the Lucene-like search layer. Bloom filters are not used in the caching strategy, but the posting lists (in the hotcache) serve a similar purpose of skipping non-matching docs.

**Observability-specific concerns:** Quickwit’s caches are designed for log/traces use. High-cardinality tags can be pruned via metadata: Quickwit records tags with cardinality below a threshold to enable split pruning ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=Quickwit%20also%20provides%20pruning%20on,the%20field%20is%20less%20than)). If tag cardinality is very high, Quickwit still uses inverted indexes (footers) but does not rely on in-memory caches for those tags. Queries on recent data simply hit all splits up to now; since splits are time-sliced, pruning by timestamp is highly effective (only relevant splits are queried). Thus the cache differentiation is naturally time-based: recent splits have their hotcache/fast fields cached if repeatedly accessed. Historical data (older splits) may not be in memory and require fetch; again, rendezvous hashing concentrates repeat queries on the same nodes, eventually loading those splits. Quickwit’s design assumes most queries cover contiguous time ranges with shared filters, so caching at the split level yields big wins. There’s no explicit “recent vs historical” differentiation beyond split assignment.

# Comparison of Query Caching in Elasticsearch, GreptimeDB, InfluxDB, and Quickwit

|Feature / System|**Elasticsearch**|**GreptimeDB**|**InfluxDB**|**Quickwit**|
|---|---|---|---|---|
|**Cache focus**|Query/filter bitsets (inverted index) and full-response caching|Data page cache (Parquet read/write cache)|Write-buffer (WAL/memtable) and tag index cache|Search index footers (“hotcache”), fast-fields, partial results|
|**Core cache layers**|_IndicesQueryCache_ (node-level bitsets) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=Elasticsearch%20features%20a%20IndicesQueryCache%20class,takes%20up%20two%20configuration%20options](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=Elasticsearch%20features%20a%20IndicesQueryCache%20class,takes%20up%20two%20configuration%20options))); _IndicesRequestCache_ (shard-level hits) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder))|_Write cache_ (recent data on disk) and _Read cache_ (Parquet pages on disk) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|Greptime]([https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache))) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|
|**Cache algorithm**|LRU (by heap weight and count) in Lucene’s `LRUQueryCache`; bitsets (Roaring) for filters ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=public%20LRUQueryCache,03f%29%2C%20250%29%3B](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=public%20LRUQueryCache,03f%29%2C%20250%29%3B))); request cache LRU by size ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder))|LRU on local disk; write-through for new data; caches Parquet column pages ([Performance Tuning Tips|GreptimeDB Documentation]([https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=match%20at%20L132%20,total%20disk%20space%20for%20it](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=match%20at%20L132%20,total%20disk%20space%20for%20it))) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|
|**Invalidation**|On segment refresh/merge (query cache); on shard refresh or write (request cache) ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=filter%20context%20are%20used%20to,total%20documents%2C%20whichever%20is%20larger)) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=the%20existing%20ways%20to%20query,set%20needs%20to%20be%20created](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=the%20existing%20ways%20to%20query,set%20needs%20to%20be%20created))). Always consistent (no stale data).|Evicted by size/TTL; on rewrite of Parquet pages. No “stale data” because writes go to new files ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|Greptime]([https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=3,low%20latency%2C%20bypassing%20object%20storage](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=3,low%20latency%2C%20bypassing%20object%20storage))) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|
|**Memory usage**|Uses JVM heap (default ~10% for query cache) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010))). Counts RAM of bitsets+keys. Can pin significant RAM. Request cache is also in-heap (configurable size) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)).|Primarily local disk; uses heap minimally for metadata. Cache capacity (default 5GiB) uses SSD (read/write cache files) ([Configuration|GreptimeDB Documentation]([https://docs.greptime.com/user-guide/deployments/configuration#:~:text=GreptimeDB%20enables%20local%20file%20caching,5GiB](https://docs.greptime.com/user-guide/deployments/configuration#:~:text=GreptimeDB%20enables%20local%20file%20caching,5GiB))).|
|**High-cardinality data**|High-card filters create sparse bitsets. Query cache may not help if filters are single-use (policy avoids caching low-frequency terms) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=FrequencyTrackingRingBuffer%20%28implemented%20using%20fixed,the%20minimum%20frequency%20to%20be](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=FrequencyTrackingRingBuffer%20%28implemented%20using%20fixed,the%20minimum%20frequency%20to%20be))). Inverted index handles cardinality, but caching offers less benefit.|Columnar storage compresses high-card data. Cache pages by time spans, cardinality not directly addressed. High-card tags mean more data pages to load.|TSI can index many series, but too many unique series can blow up index. The series-ID cache is small (default 100) and helps repeated lookups of tag filters ([InfluxDB configuration options|
|**Time-series patterns**|Time filters often rewritten to `match_all` for older indices (cacheable) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20second%20visualization%20is%20very,000004](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20second%20visualization%20is%20very,000004))). Filter caching effectively handles fixed time ranges.|Built for TS: stores recent time-sorted data in Memtable/write cache (fast path) ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking|Greptime]([https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=,millisecond%20query%20latency](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=,millisecond%20query%20latency))). Read cache of Parquet pages accelerates range scans.|
|**Query pattern impact**|Repeated identical queries/filters can hit caches. Aggregation queries (`size=0`) benefit from request cache. Profiler queries not cached. QueryCache is heuristic: only filters seen >1× get cached ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=However%2C%20things%20are%20a%20little,the%20minimum%20frequency%20to%20be](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=However%2C%20things%20are%20a%20little,the%20minimum%20frequency%20to%20be))).|Repeated scans of same time ranges reuse cached pages. Metadata caches speed up planning on repeated queries. Warm-up needed on new data.|Queries that hit frequently-used series predicates reuse the small index cache. Many ad-hoc queries will largely re-scan. Writes and retention can make caching less effective for rapidly changing series.|
|**Distributed cache**|Per-node, per-shard. No cross-node coherence. Caches tied to shards on that node ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=Elasticsearch%20features%20a%20IndicesQueryCache%20class,takes%20up%20two%20configuration%20options](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=Elasticsearch%20features%20a%20IndicesQueryCache%20class,takes%20up%20two%20configuration%20options))) ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20component%20responsible%20for%20caching,queries%20that%20are%20being%20profiled](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=The%20component%20responsible%20for%20caching,queries%20that%20are%20being%20profiled))). Rendezvous or shard-IDs direct queries to nodes with required data, maximizing reuse. On node fail/join, caches are empty and fill on demand.|Each node has its own local caches. No replication of cached pages. Queries on a given shard always hit the same node (thanks to shard routing); caches warm after restarts organically. No explicit warming.|
|**Cache metrics**|`_nodes/stats/indices/query_cache` and `request_cache` APIs report hits/misses ([Elasticsearch caching deep dive: Boosting query speed one cache at a time|Elastic Blog]([https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition,rates%20and%20other%20information%20via](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition,rates%20and%20other%20information%20via))).|Exposes `greptime_mito_cache_hit/miss/bytes` for the in-engine caches ([Performance Tuning Tips|GreptimeDB Documentation]([https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss))). No user-level query cache stats (it is data caching).|
|**Eviction policy**|LRU by weight (heap bytes) for both caches ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)). Request cache also supports TTL. Query cache does not use time, only usage.|LRU on disk pages/files. Write cache can evict oldest or based on TTL. Read cache evicts least-recently used pages.|Memtable is flushed when full (size threshold) or idle. Series-index cache uses simple LRU: least-recent tag filter evicted after 100 entries.|LRU by recency for footer and fast-field caches (capacity in bytes). Split cache evicts oldest split (FIFO) or by LRU when space full. Partial cache uses LRU on query key.|
|**Freshness vs latency**|Always fresh: any write triggers cache invalidation (on refresh). No stale data returned. Consistency prioritized.|Strong freshness for recent data (write cache always current). Cached pages are immutable once written; no staleness issue.|Consistent reads: query merges live cache + TSM. If index cache stale, new points still seen via memtable.|Immutable by design: cached data never goes stale. Freshness is trivial; only new splits add new data.|

**Best workloads and trade-offs:** For high-cardinality log data with frequent full-text search, Elasticsearch and Quickwit shine due to their inverted-index caches – ES for flexible query DSLs, Quickwit for cloud-native scale. For pure time-series metrics or high-ingest observability, GreptimeDB and InfluxDB are optimized: Greptime’s Parquet/page caches serve range queries efficiently, and Influx’s memtable accelerates recent writes and queries. Under heavy multi-node scaling, Quickwit’s rendezvous hashing offers excellent horizontal scalability (adding nodes reduces search latency linearly) ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=cluster%20using%20rendez,returns%20them%20to%20the%20client)), whereas Elasticsearch relies on shard reallocation (more static scaling). InfluxDB’s clustering (enterprise) handles shards and replicas but its caching remains per-node. Greptime scales shards via its distributed LSM design, but cache is always local to node. In terms of memory overhead, Elasticsearch’s query caches can use the most heap (since bitsets scale with index size), Quickwit uses moderate heap (big footers cached), Greptime uses disk for caches, and Influx uses RAM for writes and small index caches. Consistency concerns are minimal for all (none allow stale queries), so designs favor performance with strong correctness.

In summary, Elasticsearch provides fine-grained filter/result caching with sophisticated eviction and tracking ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=However%2C%20things%20are%20a%20little,the%20minimum%20frequency%20to%20be)) ([Caching In Elasticsearch - OpenSource Connections](https://opensourceconnections.com/blog/2017/07/10/caching_in_elasticsearch/#:~:text=filter%20context%20are%20used%20to,total%20documents%2C%20whichever%20is%20larger)), GreptimeDB provides a multi-layer data cache optimized for time-series storage ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache)) ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss)), InfluxDB relies on its write-cache and small index caches ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=Cache)) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)), and Quickwit caches index structures (footers, columns) to accelerate log queries ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G)) ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=,accessed%20very%20frequently%20by%20users)). Each system balances memory vs latency differently to suit its workloads.

**Sources:** Official documentation and code from Elasticsearch ([Elasticsearch caching deep dive: Boosting query speed one cache at a time | Elastic Blog](https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=,this%20cache%2C%20defaults%20to%2010)) ([elasticsearch/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java at 7.11 · elastic/elasticsearch · GitHub](https://github.com/elastic/elasticsearch/blob/7.11/server/src/main/java/org/elasticsearch/indices/IndicesRequestCache.java#:~:text=CacheBuilder,builder)), GreptimeDB docs and blogs ([GreptimeDB Storage Architecture Deep Dive - The Secrets Behind JSONBench's Top Ranking | Greptime](https://greptime.com/blogs/2025-03-26-greptimedb-storage-architecture#:~:text=To%20optimize%20historical%20queries%2C%20GreptimeDB,implements%20a%20dedicated%20read%20cache)) ([Performance Tuning Tips | GreptimeDB Documentation](https://docs.greptime.com/0.11/user-guide/administration/performance-tuning-tips/#:~:text=greptime_mito_cache_bytes%20gauge%20Size%20of%20cached,Total%20count%20of%20cache%20miss)), InfluxDB documentation ([InfluxDB storage engine | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/internals/storage-engine/#:~:text=Cache)) ([InfluxDB configuration options | InfluxDB OSS v2 Documentation](https://docs.influxdata.com/influxdb/v2/reference/config-options/#:~:text=storage)), and Quickwit documentation/blogs ([Querying | Quickwit](https://quickwit.io/docs/main-branch/overview/concepts/querying#:~:text=1,and%20returns%20them%20to%20the)) ([Scaling search to terabytes on a budget | Quickwit](https://quickwit.io/blog/benchmarking-quickwit-engine-on-an-adversarial-dataset#:~:text=1,1G)), as cited above. Tables and discussion draw from these sources.